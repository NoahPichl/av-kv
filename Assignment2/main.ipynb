{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import ObjectDetection.Open3D_ML.ml3d as _ml3d\n",
    "import ObjectDetection.Open3D_ML.ml3d.torch as tml3d\n",
    "from ObjectDetection.TaskDataset import TaskDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosen Model\n",
    "\n",
    "PointPillars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "Implemented most of the dataloading and preprocessing in TaskDataset.py <br>\n",
    "Load model weigths from pointpillars_waymo.pth <br>\n",
    "The model configuration and general pipelinesettings are defined in pointpillars_waymo.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = \"/workspaces/AutomotiveVehicles/Assignment2/ObjectDetection/pointpillars_waymo.yml\"\n",
    "cfg =  _ml3d.utils.Config.load_from_file(cfg_file)\n",
    "\n",
    "model = tml3d.models.PointPillars(**cfg.model)\n",
    "dataset = TaskDataset(cfg.dataset)\n",
    "pipeline = tml3d.pipelines.ObjectDetection(model, dataset=dataset, device=\"gpu\", **cfg.pipeline)\n",
    "\n",
    "# download the weights.\n",
    "ckpt_folder = \"./logs/\"\n",
    "os.makedirs(ckpt_folder, exist_ok=True)\n",
    "ckpt_path = ckpt_folder + \"pointpillars_waymo_202211200158utc_seed2_gpu16.pth\"\n",
    "pointpillar_url = \"https://storage.googleapis.com/open3d-releases/model-zoo/pointpillars_waymo_202211200158utc_seed2_gpu16.pth\"\n",
    "if not os.path.exists(ckpt_path):\n",
    "    cmd = \"wget {} -O {}\".format(pointpillar_url, ckpt_path)\n",
    "    os.system(cmd)\n",
    "\n",
    "# load the parameters.\n",
    "pipeline.load_ckpt(ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from typing import Tuple\n",
    "\n",
    "def pcl_to_bev(pcl:np.ndarray, configs: edict) -> np.ndarray:\n",
    "    \"\"\"Computes the bev map of a given pointcloud. \n",
    "    \n",
    "    For generality, this method can return the bev map of the available \n",
    "    channels listed in '''BEVConfig.VALID_CHANNELS'''. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        pcl (np.ndarray): pointcloud as a numpy array of shape [n_points, m_channles] \n",
    "        configs (Dict): configuration parameters of the resulting bev_map\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        bev_map (np.ndarray): bev_map as numpy array of shape [len(config.channels), configs.bev_height, configs.bev_width ]\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove lidar points outside detection area and with too low reflectivity\n",
    "    mask = np.where((pcl[:, 0] >= configs.lims.x[0]) & (pcl[:, 0] <= configs.lims.x[1]) &\n",
    "                    (pcl[:, 1] >= configs.lims.y[0]) & (pcl[:, 1] <= configs.lims.y[1]) &\n",
    "                    (pcl[:, 2] >= configs.lims.z[0]) & (pcl[:, 2] <= configs.lims.z[1]))\n",
    "    pcl = pcl[mask]\n",
    "\n",
    "    # shift level of ground plane to avoid flipping from 0 to 255 for neighboring pixels\n",
    "    pcl[:, 2] = pcl[:, 2] - configs.lims.z[0]  \n",
    "\n",
    "    # Convert sensor coordinates to bev-map coordinates (center is bottom-middle)\n",
    "    # compute bev-map discretization by dividing x-range by the bev-image height\n",
    "    bev_x_discret = (configs.lims.x[1] - configs.lims.x[0]) / configs.bev_height\n",
    "    bev_y_discret = (configs.lims.y[1] - configs.lims.y[0]) / configs.bev_width\n",
    "    ## transform all metrix x-coordinates into bev-image coordinates    \n",
    "    pcl_cpy = np.copy(pcl)\n",
    "    pcl_cpy[:, 0] = np.int_(np.floor(pcl_cpy[:, 0] / bev_x_discret))\n",
    "    # transform all y-coordinates making sure that no negative bev-coordinates occur\n",
    "    pcl_cpy[:, 1] = np.int_(np.floor(pcl_cpy[:, 1] / bev_y_discret) + (configs.bev_width + 1) / 2) \n",
    "    # Create BEV map\n",
    "    bev_map = np.zeros((3, configs.bev_height, configs.bev_width))\n",
    "    # Compute height and density channel\n",
    "    pcl_height_sorted, counts = sort_and_map(pcl_cpy, 2, return_counts=True)\n",
    "    xs = np.int_(pcl_height_sorted[:, 0])\n",
    "    ys = np.int_(pcl_height_sorted[:, 1])\n",
    "    # Fill height map\n",
    "    normalized_height = pcl_height_sorted[:, 2]/float(np.abs(configs.lims.z[1] - configs.lims.z[0]))\n",
    "    height_map = np.zeros((configs.bev_height + 1, configs.bev_width + 1))\n",
    "    height_map[xs,ys] = normalized_height\n",
    "    \n",
    "    # Fill density map\n",
    "    normalized_density = np.minimum(1.0, np.log(counts + 1) / np.log(64))\n",
    "    density_map = np.zeros((configs.bev_height + 1, configs.bev_width + 1))\n",
    "    density_map[xs,ys] = normalized_density\n",
    "\n",
    "    # Compute intesity channel\n",
    "    pcl_cpy[pcl_cpy[:,3]>configs.lims.intensity[1],3] = configs.lims.intensity[1]\n",
    "    pcl_cpy[pcl_cpy[:,3]<configs.lims.intensity[0],3] = configs.lims.intensity[0]\n",
    "    \n",
    "    pcl_int_sorted, _ = sort_and_map(pcl_cpy, 3, return_counts=False)\n",
    "    xs = np.int_(pcl_int_sorted[:, 0])\n",
    "    ys = np.int_(pcl_int_sorted[:, 1])\n",
    "    normalized_int = pcl_int_sorted[:, 3]/(np.amax(pcl_int_sorted[:, 3])-np.amin(pcl_int_sorted[:, 3]))\n",
    "    intensity_map = np.zeros((configs.bev_height + 1, configs.bev_width + 1))\n",
    "    intensity_map[xs,ys] = normalized_int\n",
    "    \n",
    "    # Fill BEV \n",
    "    bev_map[2,:,:] = density_map[:configs.bev_height, :configs.bev_width]\n",
    "    bev_map[1,:,:] = height_map[:configs.bev_height, :configs.bev_width]\n",
    "    bev_map[0,:,:] = intensity_map[:configs.bev_height, :configs.bev_width]\n",
    " \n",
    "    return bev_map\n",
    "\n",
    "def sort_and_map(pcl: np.ndarray, channel_index: int, return_counts:bool=False) ->Tuple[np.ndarray,np.ndarray]:\n",
    "    \"\"\"Function to re-arrange elements in poincloud by sorting first by x, then y, then -channel.\n",
    "    This function allows users to map a pointcloud channel to a top view image (in z axis) of that channel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        pcl (np.ndarray): Input pointcloud of of shape [n_points, m_channles]\n",
    "        channel_index (int): Index of channel to take into account as third factor, \n",
    "                             when sorting the pointcloud.\n",
    "        return_counts (bool): True to return the counts on points per cell. Used for density channel\n",
    "    Returns\n",
    "     ----------\n",
    "       channel_map (np.ndarray): [description]\n",
    "       counts (np.ndarray): [description]\n",
    "       \n",
    "    \"\"\"\n",
    "\n",
    "    idx= np.lexsort((-pcl[:, channel_index], pcl[:, 1], pcl[:, 0]))\n",
    "    pcl_sorted = pcl[idx]\n",
    "    counts = None\n",
    "    # extract all points with identical x and y such that only the maximum value of the channel is kept\n",
    "    if return_counts:\n",
    "        _, indices, counts = np.unique(pcl_sorted[:, 0:2], axis=0, return_index=True, return_counts=return_counts)\n",
    "    else:\n",
    "        _, indices = np.unique(pcl_sorted[:, 0:2], axis=0, return_index=True)\n",
    "    return (pcl_sorted[indices], counts)\n",
    "\n",
    "def show_bev_map(bev_map: np.ndarray) -> None:\n",
    "    \"\"\"Function to show bev_map as an RGB image\n",
    "\n",
    "    By default, the image will only show the 3 first channels of `bev_map`. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        bev_map (np.ndarray): bev_map as numpy array of shape `[len(config.channels), configs.bev_height, configs.bev_width ]` \n",
    "    \"\"\"\n",
    "    bev_image: np.ndarray =  (np.swapaxes(np.swapaxes(bev_map,0,1),1,2)*255).astype(np.uint8)\n",
    "    mask: np.ndarray = np.zeros_like(bev_image[:,:,0])\n",
    "\n",
    "\n",
    "    height_image = Image.fromarray(np.dstack((bev_image[:, :, 0],mask,mask)))\n",
    "    den_image = Image.fromarray(np.dstack((mask,bev_image[:, :, 1],mask)))\n",
    "    int_image = Image.fromarray(np.dstack((mask,mask,bev_image[:, :, 2])))\n",
    "\n",
    "    int_image.show()\n",
    "    den_image.show()\n",
    "    height_image.show()\n",
    "    Image.fromarray(bev_image).show()\n",
    "\n",
    "\n",
    "configs = edict()\n",
    "configs.lims = edict()\n",
    "configs.lims.x = [0, 50]\n",
    "configs.lims.y = [-25, 25]\n",
    "configs.lims.z = [-1.5, 3]\n",
    "configs.lims.intensity = [0, 1.0]\n",
    "configs.bev_height = 640\n",
    "configs.bev_width = 640\n",
    "\n",
    "bev_map = pcl_to_bev(pcl, configs)\n",
    "show_bev_map(bev_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Multi Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenCV for visualization\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import tools.frame_pb2 as fpb\n",
    "import tools.dataset_tools as dataset_tools\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "import cv2\n",
    "\n",
    "## Constants\n",
    "max_allowed_missed_frames = 5\n",
    "update_tracks_threshold = 30\n",
    "cost_matrix = np.zeros((1, 1), dtype=float)\n",
    "video_path = \"./out.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frame(filename):\n",
    "    frame = dataset_tools.read_frame(filename)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_detections_from_camera(camera):\n",
    "    detections = []\n",
    "    for detection in camera.detections:\n",
    "        # Assuming bbox is [x0, y0, width, height]\n",
    "        # Convert bbox to [x_center, y_center]\n",
    "        x_center = detection.bbox[0] #- detection.bbox[2] / 2\n",
    "        y_center = detection.bbox[1] #- detection.bbox[3] / 2\n",
    "        detections.append(np.array([x_center, y_center]))\n",
    "    return detections\n",
    "\n",
    "def extract_detections_from_lidar(lidar):\n",
    "    detections = []\n",
    "    for detection in lidar.detections:\n",
    "        # Assuming pos is [x, y, z]\n",
    "        # Use x and y for 2D tracking\n",
    "        detections.append(np.array([detection.pos[0], detection.pos[1]]))\n",
    "    return detections\n",
    "\n",
    "def extract_detections(frame):\n",
    "    detections = []\n",
    "    for camera in frame.cameras:\n",
    "        detections.extend(extract_detections_from_camera(camera))\n",
    "    for lidar in frame.lidars:\n",
    "        detections.extend(extract_detections_from_lidar(lidar))\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filter Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kalman Filter\n",
    "class KalmanFilter:\n",
    "    def __init__(self, dt, process_noise_std, measurement_noise_std):\n",
    "        # Time step\n",
    "        self.dt = dt\n",
    "\n",
    "        # State transition model matrix (F)\n",
    "        self.F = np.array([\n",
    "            [1, 0, dt, 0],  # Position x and velocity influence\n",
    "            [0, 1, 0, dt],  # Position y and velocity influence\n",
    "            [0, 0, 1, 0],   # Velocity x\n",
    "            [0, 0, 0, 1]    # Velocity y\n",
    "        ])\n",
    "\n",
    "        # Process noise covariance matrix (Q)\n",
    "        q = process_noise_std**2\n",
    "        self.Q = q * np.array([\n",
    "            [dt**4/4, 0, dt**3/2, 0],\n",
    "            [0, dt**4/4, 0, dt**3/2],\n",
    "            [dt**3/2, 0, dt**2, 0],\n",
    "            [0, dt**3/2, 0, dt**2]\n",
    "        ])\n",
    "\n",
    "        # Measurement model matrix (H)\n",
    "        self.H = np.array([\n",
    "            [1, 0, 0, 0],  # Measuring position x\n",
    "            [0, 1, 0, 0]   # Measuring position y\n",
    "        ])\n",
    "\n",
    "        # Observation noise covariance matrix (R)\n",
    "        r = measurement_noise_std**2\n",
    "        self.R = r * np.eye(2)\n",
    "\n",
    "        # Initial state estimate and covariance matrix (not initialized yet)\n",
    "        self.x = None\n",
    "        self.P = None\n",
    "\n",
    "    def initialize(self, initial_position, initial_velocity=None):\n",
    "        \"\"\" Initialize the state and covariance matrices \"\"\"\n",
    "        # print(f\"Initializing Kalman Filter with initial position: {initial_position}\")\n",
    "        if initial_velocity is None:\n",
    "            initial_velocity = [0, 0]  # Assume initial velocity is 0 if not provided\n",
    "        self.x = np.array([initial_position[0], initial_position[1], initial_velocity[0], initial_velocity[1]])\n",
    "        self.P = np.eye(4)  # High initial uncertainty\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\" Predict the state and covariance after time dt \"\"\"\n",
    "        # print(f'Predicting Kalman Filter with dt = {self.dt}')\n",
    "        self.x = np.dot(self.F, self.x)\n",
    "        self.P = np.dot(self.F, np.dot(self.P, self.F.T)) + self.Q\n",
    "\n",
    "    def update(self, measurement):\n",
    "        \"\"\" Update the state by a new measurement \"\"\"\n",
    "        # print(f'Updating Kalman Filter with measurement = {measurement}')\n",
    "        z = np.array(measurement)\n",
    "        y = z - np.dot(self.H, self.x)  # Measurement residual\n",
    "        S = np.dot(self.H, np.dot(self.P, self.H.T)) + self.R  # Residual covariance\n",
    "        K = np.dot(self.P, np.dot(self.H.T, np.linalg.inv(S)))  # Kalman gain\n",
    "        self.x = self.x + np.dot(K, y)\n",
    "        I = np.eye(self.F.shape[0])\n",
    "        self.P = np.dot((I - np.dot(K, self.H)), self.P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracker Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tracker Class\n",
    "class Tracker:\n",
    "    def __init__(self):\n",
    "        self.tracks = []\n",
    "        self.next_id = 1\n",
    "\n",
    "    def update_tracks(self, detections):\n",
    "        # Call predict on all existing tracks\n",
    "        for track in self.tracks:\n",
    "            track['kf'].predict()\n",
    "\n",
    "        if not self.tracks:  # If no tracks exist, initialize tracks with each detection\n",
    "            for det in detections:\n",
    "                kf = KalmanFilter(dt=0.1, process_noise_std=1.0, measurement_noise_std=1.0)\n",
    "                kf.initialize(det)\n",
    "                self.tracks.append({'id': self.next_id, 'kf': kf, 'last_detected': 0})\n",
    "                self.next_id += 1\n",
    "            return\n",
    "\n",
    "        # Association step\n",
    "        cost_matrix = np.zeros((len(detections), len(self.tracks)))\n",
    "        for d_index, detection in enumerate(detections):\n",
    "            for t_index, track in enumerate(self.tracks):\n",
    "                predicted_position = track['kf'].x[:2]\n",
    "                cost_matrix[d_index, t_index] = np.linalg.norm(detection - predicted_position)\n",
    "\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        all_detections = set(range(len(detections)))\n",
    "        all_tracks = set(range(len(self.tracks)))\n",
    "\n",
    "        used_detections = set(row_ind)\n",
    "        unused_detections = all_detections - used_detections\n",
    "        used_tracks = set(col_ind)\n",
    "        unused_tracks = all_tracks - used_tracks\n",
    "\n",
    "        # Update associated tracks\n",
    "        for d, t in zip(row_ind, col_ind):\n",
    "            self.tracks[t]['kf'].update(detections[d])\n",
    "            self.tracks[t]['last_detected'] = 0\n",
    "\n",
    "        # Create new tracks for unmatched detections\n",
    "        for d in unused_detections:\n",
    "            kf = KalmanFilter(dt=0.1, process_noise_std=1.0, measurement_noise_std=1.0)\n",
    "            kf.initialize(detections[d])\n",
    "            self.tracks.append({'id': self.next_id, 'kf': kf, 'last_detected': 0})\n",
    "            self.next_id += 1\n",
    "\n",
    "        # Increase age of all tracks and remove old ones\n",
    "        self.prune_tracks()\n",
    "\n",
    "    def prune_tracks(self):\n",
    "        self.tracks = [track for track in self.tracks if track['last_detected'] < 5]\n",
    "        for track in self.tracks:\n",
    "            track['last_detected'] += 1\n",
    "\n",
    "    # def visualize_tracks(self, frame_index):\n",
    "    #     plt.figure(figsize=(10, 8))\n",
    "    #     for track in self.tracks:\n",
    "    #         plt.plot(track['kf'].x[0], track['kf'].x[1], 'bo')\n",
    "    #         plt.text(track['kf'].x[0], track['kf'].x[1], str(track['id']), color=\"red\")\n",
    "    #     plt.title(f\"Frame {frame_index}\")\n",
    "    #     plt.grid(True)\n",
    "    #     plt.show()\n",
    "    \n",
    "    def visualize_tracks_img(self, image, detections, frame_index):\n",
    "        \"\"\"\n",
    "        Visualize the current tracks and detections on the image.\n",
    "\n",
    "        :param image: The image array (numpy array).\n",
    "        :param tracks: List of current tracks with their Kalman Filter state estimates.\n",
    "        :param detections: List of detections as (x_center, y_center) used for initial track positions.\n",
    "        :param frame_index: Index of the current frame for title display.\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(1, figsize=(10, 8))\n",
    "        ax.imshow(image)\n",
    "        \n",
    "        # Draw detections as rectangles\n",
    "        for det in detections:\n",
    "            rect = Rectangle((det[0] - 15, det[1] - 15), 30, 30, linewidth=2, edgecolor='blue', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        \n",
    "        # Draw tracked positions as circles\n",
    "        for track in self.tracks:\n",
    "            x, y = track['kf'].x[0], track['kf'].x[1]\n",
    "            circle = Circle((x, y), 15, color='red', fill=False, linewidth=2)\n",
    "            ax.add_patch(circle)\n",
    "            ax.text(x, y, str(track['id']), color=\"white\", fontsize=12)\n",
    "\n",
    "        plt.title(f\"Frame {frame_index}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def visualize_tracks(self, image, detections, frame_index):\n",
    "        \"\"\"\n",
    "        Visualize the current tracks and detections on the image using OpenCV.\n",
    "\n",
    "        :param image: The image array (numpy array).\n",
    "        :param detections: List of detections as (x_center, y_center) used for initial track positions.\n",
    "        :param tracks: List of current tracks with their Kalman Filter state estimates.\n",
    "        :param frame_index: Index of the current frame for title display.\n",
    "        \"\"\"\n",
    "        # Convert image from RGB to BGR (OpenCV uses BGR by default)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Draw detections as rectangles\n",
    "        for det in detections:\n",
    "            top_left = (int(det[0] - 15), int(det[1] - 15))\n",
    "            bottom_right = (int(det[0] + 15), int(det[1] + 15))\n",
    "            cv2.rectangle(image, top_left, bottom_right, (255, 0, 0), 2)  # Blue rectangles\n",
    "\n",
    "        # Draw tracked positions as circles\n",
    "        for track in self.tracks:\n",
    "            center = (int(track['kf'].x[0]), int(track['kf'].x[1]))\n",
    "            cv2.circle(image, center, 15, (0, 0, 255), 2)  # Red circles\n",
    "            cv2.putText(image, str(track['id']), (center[0] + 10, center[1] + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process Frames\n",
    "def create_video_writer(frame_size, output_path='output.mp4'):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 20.0, frame_size)\n",
    "    return out\n",
    "\n",
    "def show_image(frame):\n",
    "    camera = frame.cameras[0]\n",
    "\n",
    "    img = dataset_tools.decode_img(camera)\n",
    "\n",
    "    image = Image.fromarray(img)\n",
    "    image.show()\n",
    "    return img  # Return the image array for further processing\n",
    "\n",
    "def show_video(frame):\n",
    "    camera = frame.cameras[0]\n",
    "    img = dataset_tools.decode_img(camera)\n",
    "    image = Image.fromarray(img)\n",
    "    image.show()\n",
    "    return np.array(image)  # Ensure this is RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# def process_frames(directory, tracker):\n",
    "#     for i in range(len(os.listdir(directory))):\n",
    "#         filename = f'frame_{i}.pb'\n",
    "#         frame = load_frame(os.path.join(directory, filename))\n",
    "#         image = show_image(frame)  # Ensure this returns the image array\n",
    "#         # image = show_video(frame)  # Ensure this returns the image array\n",
    "#         detections = extract_detections(frame)\n",
    "#         tracker.update_tracks(detections)\n",
    "#         tracker.visualize_tracks_img(image, detections, frame.id)\n",
    "#         # tracker.visualize_tracks(image, detections, frame.id)\n",
    "\n",
    "def process_frames(directory, tracker):\n",
    "    video_writer = None\n",
    "    first_frame = True\n",
    "\n",
    "    for i in range(len(os.listdir(directory))):\n",
    "        filename = f'frame_{i}.pb'\n",
    "        frame = load_frame(os.path.join(directory, filename))\n",
    "        image = show_video(frame)  # This should now return an RGB image array\n",
    "        detections = extract_detections(frame)\n",
    "        tracker.update_tracks(detections)\n",
    "        \n",
    "        processed_image = tracker.visualize_tracks(image, detections, frame.id)\n",
    "        \n",
    "        # visualize image on processing\n",
    "        img = show_image(frame)\n",
    "        tracker.visualize_tracks_img(img, detections, frame.id)\n",
    "        \n",
    "        if first_frame:\n",
    "            video_writer = create_video_writer((processed_image.shape[1], processed_image.shape[0]))\n",
    "            first_frame = False\n",
    "        \n",
    "        video_writer.write(processed_image)\n",
    "\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker()\n",
    "process_frames(\"../Dataset/data_2\", tracker)\n",
    "\n",
    "# Remember to close OpenCV windows once done\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
